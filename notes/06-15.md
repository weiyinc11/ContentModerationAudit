# Research Meeting #2 - 06/15
Weekly meetings established: Wed, 2 - 3:30pm

### Catch up from meeting with Danish
* Couple of Mtech Students potentially joining starting July 1st
* Datasets - utilizing LLMs to generate sets of harmful content
    *   Real Toxicity Prompts (Grey without prompt completion, toxic with)
    *   Jigsaw (Perspective API - used for Content Moderation studies)
    *   Using bad LLms to generate specialized content to violate specific policies
* Metrics
    *   Measuring moderation at different rates of toxic content within the chat, using a simple primed LLM as a baseline for measurement.
* Other Considerations
    *   Multiple levels of Moderation: Ways to test it, highlight the keywords based moderation systems
 
###  Platform Requirements
* Open source code on how to prime LLMs
* Thinking about different types of content and domains for testing such as text-based chatbots and/or the inclusion of images.
