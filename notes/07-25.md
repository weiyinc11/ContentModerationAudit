# Meeting Notes
1. Review of Bots and Experimental design / workflow
  - Bots require activation under different commands
  - Need to test whether the timeouts are due to messages sent at too quick an interval or if there is a limit to the number of bots on each streamer's chat.
     - No need for the speed of messages to be so close to the line rate limits
     - Implementing random delays that are proportional to the length of the next message could also help
2. Differences in Policies and the construction of our dataset
  - Will be using Yash's Dataset (41,000 examples of which 54% are the positives we want to focus on) on more general hate speech as a benchmark to further develop our experimental design and what exactly we would like to test.
  - Using Twitch's definition of content that AutoMod filters through, we can base our categories of content between Interpersonal Hate Speech such as bullying and aggression (content not targeted at a protected group) and Hate Speech.
  - Perhaps we will look at the aggression and microaggression datasets

  - Overall, looking at broad hatespeech and then datasets specifically for each Automod's category
3. Experimental Design Kinks worked out
  - Keeping our experimental environment as clean as possible
     - We will keep smart detection off as well as keeping levels of moderation to a binary setting.
     - Utilizing the subcategories of Hostility and Discrimination + Slurs that we can specifically activate
  - Exp #1 : non-conversational comments | Exp #2 : Conversational and includes context.. 
  - Main Considerations
     1. Benign : Hateful messages ratio
     2. The average length of a twitch stream and how often are messages coming in during a stream?
4. Metrics
  - How many messages were mod / not
  - Latency rate of detection
  - How mod depends on levels of filtering
